from abc import ABCMeta
import gym
import torch

import gym_cenvs
import numpy as np
from src.simp_mod_library.simp_mod_lib import SimpModLib
from typing import List


class BaseAgent(metaclass=ABCMeta):
    """
    Base class for constructing agents that control the complex object using passed Simple Model Library
    """
    def __init__(self, smodel_list: List[str], device: str = 'cuda:0'):
        # String that is set in derived class
        self.env_name: str = None
        # Ref to step-able mujoco-gym environment
        self.env = None

        # Devices
        self.device = device

        # Dimensionality of an action vector
        self.action_dimension: int = None

        self.model_lib = SimpModLib(smodel_list, device)

        # Keys for the online collected dataset. gt = Ground Truth, ep = episode,
        # gt_frame = raw unprocessed frame
        # all_ep_rollouts = potentially hybrid multiple model roll-outs generated by
        #  propagating the final planned actions
        self.data_keys = ["action_history",
                          "gt_state_history",
                          "gt_frame_history",
                          "rollouts"]

        # Container for the episode data collected that is global across agent
        self.episode_data = dict()
        # Initialize all the episode-specific datasets with empty lists
        for data_key in self.data_keys:
            self.episode_data[data_key] = []

    def make_agent_for_task(self):
        """
        Invoked after task specific params have been set in derived class
        :return:
        """
        self.env = gym.make(self.env_name)
        self.env.seed(0)
        self.env.action_space.seed(0)

        # TODO: Infer action dimension from the environment
        #  Check consistency of this dimension with the controls dimension of simple model lib
        self.action_dimension = 1

        return

    @classmethod
    def __new__(cls, *args, **kwargs):
        """
        Make abstract base class non-instaiable
        :param args:
        :param kwargs:
        """
        if cls is BaseAgent:
            raise TypeError(f"only children of '{cls.__name__}' may be instantiated")
        return object.__new__(cls)

    def do_episode(self):
        """
        Agent method to online interact with the complex env over an episode
        :return:
        """
        #

        # Reset episode specific parameters
        self.reset_episode()

        done, fail, reward, info = self.step()

    def step(self):
        """
        Step through the environment with a task specific agent
        :return:
        """
        # TODO: Change random actions to planned actions from controller
        # Random action for testing
        action = np.random.uniform(-1, 1)
        # Assemble action into compatible torch tensor
        actions = torch.tensor([[action]])

        # Total reward seen so far
        total_reward = 0

        self.x

    def reset_episode(self):
        """
        Reset a single episode of interaction with the environment to move on to the next episode
         within the same trial
        :return:
        """
        if self.env is None:
            raise ValueError("Environment has not been made ... cannot reset episode...")

        for data_key in self.data_keys:
            self.episode_data[data_key] = []

        # Frame returned initially from mjco-py environment has a jump from subsequent so ignore it
        _ = self.env.reset()
        obs, _, _, info = self.env.predict()

        # Reset the episode-specific state of the simple model library
        self.model_lib.reset_episode(obs)

        # Append GT state of complex environment to online collected data
        self.episode_data['gt_state_history'].append(info['state'])

    def reset_trial(self):
        """
        Reset an entire trial for a clean/fresh evaluation of MM-LVSPC
        :return:
        """
        self.model_lib.reset_trial()
